{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whales import engine_futures, db_path_futures, engine\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import text\n",
    "from models.histpricemodel import HistPrice\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with Session(engine_futures) as session:\n",
    "    _query = text(\"SELECT * FROM histprice;\")\n",
    "    #resultados = session.execute(_query).all()\n",
    "    dados = pd.read_sql(sql=_query, con=engine_futures)\n",
    "    #print(dados[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data = dados.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data['opentime'] = [datetime.fromtimestamp(time/1000) for time in edited_data['opentime']]\n",
    "edited_data['closetime'] = [datetime.fromtimestamp(time/1000) for time in edited_data['closetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = edited_data.query(\"pair == 'ADAUSDT'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('data/ada_prices_1m.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset from csv file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/ada_prices_1m.csv', parse_dates=True, index_col='opentime')\n",
    "dataset.sort_index(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Unnamed: 0', 'id', 'pair', 'ignore'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_index('opentime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sort_index(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['diff'] = dataset['close'] - dataset['open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(datetime.timestamp(dataset.index[0]) + (60 * 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset.index == datetime.fromtimestamp(datetime.timestamp(dataset.index[0]) + (60 * 60))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(df: pd.DataFrame, period: int) -> pd.DataFrame:\n",
    "    _new_df = pd.DataFrame()\n",
    "    for i in range(df.__len__() - period):\n",
    "        _tmp_df = df.loc[df.index == datetime.fromtimestamp(datetime.timestamp(df.index[i]) + (period * 60))]\n",
    "        _new_df = pd.concat([_new_df, _tmp_df['close']], axis=0)\n",
    "        \n",
    "    return _new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_v2(df: pd.DataFrame, period: int) -> pd.DataFrame:\n",
    "    _new_df = df.iloc[period:,:]\n",
    "    return _new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_targets(dataset, 60),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = get_targets_v2(dataset, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include_targets(df_base: pd.DataFrame, df_futures: pd.DataFrame) -> pd.DataFrame:\n",
    "    _tmp_prices = []\n",
    "    for i in range(len(df_futures)):\n",
    "        _tmp_prices.append(df_futures['close'][i])\n",
    "    if len(_tmp_prices) < len(df_base):\n",
    "        distance = len(df_base) - len(_tmp_prices)\n",
    "        for item in range(distance):\n",
    "            _tmp_prices.append(0)\n",
    "    df_base['target_prices'] = _tmp_prices\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = include_targets(dataset, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_test[:-60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['diff_target'] = dataset['target_prices'] - dataset['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profit(close_price, diff_target):\n",
    "    return ((diff_target * 100) / close_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['target_profit'] = calculate_profit(dataset['close'], dataset['diff_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from finta import TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['RSI'] = TA.RSI(dataset, period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['MSD'] = TA.MSD(dataset, period=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['OBV'] = TA.OBV(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['EMA'] = TA.EMA(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbands = TA.BBANDS(dataset, period=9, std_multiplier=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['SDT_M'] = dataset['diff'].rolling(window=60).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['VFI'] = TA.VFI(dataset, period=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_points = TA.PIVOT(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[61:-60].to_csv('data/ada_prices_with_more_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['opentime', 'open', 'high', 'low', 'close', 'closetime', 'quoteassetvolume', 'takerbuybaseassetvolume', 'takerbuyquoteassetvolume', 'target_prices', 'target_profit'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[61:-60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['OBV'].fillna(0, inplace=True)\n",
    "dataset['RSI'].fillna(0, inplace=True)\n",
    "dataset['MSD'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.columns = ['close', 'volume', 'RSI', 'MSD', 'OBV', 'numberoftrades', 'diff', 'target_prices', 'diff_target', 'target_profit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('data/ada_prices_with_more_features_norm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/ada_prices_with_more_features_norm.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_treino = int(len(dataset) * 0.80)\n",
    "treino, teste = dataset[0:tamanho_treino], dataset[tamanho_treino:len(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando quais dados servirão para treino e para teste\n",
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "ax.plot(treino['diff_target'], label='treino', linewidth=1)\n",
    "ax.plot(teste['diff_target'], label='teste', linewidth=1)\n",
    "ax.set_ylabel('Função', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando quais dados servirão para treino e para teste\n",
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "ax.plot(treino['diff'], label='treino', linewidth=1)\n",
    "ax.plot(teste['diff'], label='teste', linewidth=1)\n",
    "ax.set_ylabel('Função', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_direction(dataset: pd.DataFrame, direction_reference_col = 'diff_target') -> pd.DataFrame:\n",
    "    index_target_col = dataset.columns.get_loc(direction_reference_col)\n",
    "    _direction = []\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset.iloc[i,index_target_col] > 0: _direction.append(1)\n",
    "        elif dataset.iloc[i,index_target_col] < 0: _direction.append(-1)\n",
    "        else: _direction.append(0)\n",
    "    dataset['direction'] = _direction\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = price_direction(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['direction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_treino = int(len(dataset) * 0.80)\n",
    "treino, teste = dataset[0:tamanho_treino], dataset[tamanho_treino:len(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Criando uma função para as janelas temporais. A saída será dois arrays, o primeiro contendo várias janelas do dataset, e o\n",
    "# segundo contendo valores a serem previstos\n",
    "def gera_dataset(dataset, tamanho_janela = 1, col_target_name = 'Close'):\n",
    "    dataA, dataB = [], []\n",
    "    for i in range(len(dataset)-tamanho_janela): # lembre-se que os datasets têm índices começando em zero\n",
    "        a = dataset[i:(i+tamanho_janela)].copy()\n",
    "        a.drop(col_target_name, axis=1, inplace=True)\n",
    "        a = a.to_numpy()\n",
    "        dataA.append(a)\n",
    "        try:\n",
    "            index_col = dataset.columns.get_loc(col_target_name)\n",
    "            b = dataset.iloc[i+tamanho_janela,index_col].copy()\n",
    "            #print(b)\n",
    "            #b = b.to_numpy()\n",
    "            \n",
    "            dataB.append(b)\n",
    "        except KeyError:\n",
    "            break \n",
    "    return np.asarray(dataA, dtype=np.float32), np.asarray(dataB, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.shape, teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste.columns.get_loc('diff_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função nos datasets de treino e teste que já criamos:\n",
    "tamanho_janela=60\n",
    "x_treino, y_treino = gera_dataset(treino, tamanho_janela=tamanho_janela, col_target_name='diff_target')\n",
    "x_teste, y_teste = gera_dataset(teste, tamanho_janela=tamanho_janela, col_target_name='diff_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino.shape, y_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste.shape, teste.head(), teste.iloc[0,-1], x_teste.shape, x_teste[0][0][-1], y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='-1'\n",
    "os.environ[\"KERAS_BACKEND\"] = 'tensorflow'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "from finta import TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo LSTM:\n",
    "modelo = Sequential()\n",
    "#modelo.add(LSTM(4, batch_input_shape = (2, x_treino.shape[1], x_treino.shape[2]), stateful = True))\n",
    "modelo.add(LSTM(20, input_shape = (x_treino.shape[1], x_treino.shape[2]), dropout=0.05))\n",
    "\n",
    "\n",
    "modelo.add(Dense(1, activation='relu')) # Saída da LSTM\n",
    "modelo.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "modelo.fit(x_treino, y_treino, epochs = 200, batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "#modelo.add(LSTM(4, batch_input_shape = (2, x_treino.shape[1], x_treino.shape[2]), stateful = True))\n",
    "modelo.add(LSTM(20, input_shape = (x_treino.shape[1], x_treino.shape[2]), dropout=0.05))\n",
    "\n",
    "\n",
    "modelo.add(Dense(1, activation='relu')) # Saída da LSTM\n",
    "modelo.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.load_weights('save/lstm_price_predict_new.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_dataset_size = np.zeros(shape=(y_treino.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_dataset_size[:,-1] = y_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_treino_dataset_size = y_treino\n",
    "y_treino_dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_treino_dataset_size = y_treino\n",
    "#y_treino_dataset_size = y_treino_dataset_size.reshape(1,-1)\n",
    "y_treino = scaler.inverse_transform(y_treino_dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "index_col = dataset.columns.get_loc('diff_target')\n",
    "# Fazendo as previsões e avaliando a performance\n",
    "previsoes_treino = modelo.predict(x_treino)\n",
    "# A previsão tem como resultado um array de dimensões (n_amostras, 1), então se tentarmos executar o inverso da normalização\n",
    "# diretamente com esses dados, teremos uma mensagem de erro, afinal a normalização foi aplicada em um dataset de dimensões:\n",
    "# (n_amostras, 79), ou seja, a função scaler.inverse_transform não saberá o que fazer para gerar o inverso das outras 78 colunas.\n",
    "# Portanto iremos primeiro gerar uma matriz com a mesma quantidade de colunas de x_treino (preenchida com zeros), depois iremos\n",
    "# colocar o array de previsões em uma coluna dessa matriz (no lugar onde estava o price_actual), então poderemos aplicar a função\n",
    "# scaler.inverse_transform e depois coletar somente a coluna que nos interessa.\n",
    "# Obs: para descobrir qual o índice da coluna que possui a feature \"price actual\", basta utilizar o código: \n",
    "# treino.columns.get_loc(\"price actual\")\n",
    "\n",
    "# Previsões com os dados de treino:\n",
    "previsoes_treino_dataset_size = np.zeros(shape=(len(previsoes_treino), x_treino.shape[2] +1))\n",
    "previsoes_treino_dataset_size[:,index_col] = previsoes_treino[:,0]\n",
    "previsoes_treino = scaler.inverse_transform(previsoes_treino_dataset_size)[:,index_col]\n",
    "\n",
    "# Previsões com os dados de teste:\n",
    "previsoes_teste = modelo.predict(x_teste)\n",
    "previsoes_teste_dataset_size = np.zeros(shape=(len(previsoes_teste), x_teste.shape[2] +1))\n",
    "previsoes_teste_dataset_size[:,index_col] = previsoes_teste[:,0]\n",
    "previsoes_teste = scaler.inverse_transform(previsoes_teste_dataset_size)[:,index_col]\n",
    "\n",
    "# Invertendo a normalização das variáveis target:\n",
    "y_treino_dataset_size = np.zeros(shape=(len(y_treino), x_treino.shape[2] +1))\n",
    "y_treino_dataset_size[:,index_col] = y_treino\n",
    "y_treino = scaler.inverse_transform(y_treino_dataset_size)[:,index_col]\n",
    "\n",
    "y_teste_dataset_size = np.zeros(shape=(len(y_teste), x_teste.shape[2] +1))\n",
    "y_teste_dataset_size[:,index_col] = y_teste\n",
    "y_teste = scaler.inverse_transform(y_teste_dataset_size)[:,index_col]\n",
    "\n",
    "# Calculando o RMSE:\n",
    "score_treino = math.sqrt(mean_squared_error(y_treino, previsoes_treino))\n",
    "print('Score em Treino: %.2f RMSE' % (score_treino))  \n",
    "score_teste = math.sqrt(mean_squared_error(y_teste, previsoes_teste))\n",
    "print('Score em Teste: %.2f RMSE' % (score_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando as previsões do modelo:\n",
    "# previsto = teste[tamanho_janela:].copy()  \n",
    "# previsto['Close'] = previsoes_teste # coloca os valores das previsoes do modelo dentro dessa variável\n",
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "# treino['Close'] = scaler.inverse_transform(treino['Close'].values.reshape(-1,1))\n",
    "# teste['Close'] = scaler.inverse_transform(teste['Close'].values.reshape(-1,1))\n",
    "#ax.plot(y_treino, label='treino', linewidth=2)\n",
    "ax.plot(y_teste[101:500], label='teste', linewidth=2)\n",
    "ax.plot(previsoes_teste[101:500], label='previsões', linewidth=1)\n",
    "ax.set_ylabel('Função', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Trader - Course Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6355/3301107732.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('data/ada_prices.csv', index_col=0, parse_dates=True)\n",
    "#df0.dropna(axis=0, how='all', inplace=True)\n",
    "#df0.dropna(axis=1, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>BB_UPPER</th>\n",
       "      <th>BB_MIDDLE</th>\n",
       "      <th>BB_LOWER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-01 03:59:59.999</th>\n",
       "      <td>0.05516</td>\n",
       "      <td>0.05538</td>\n",
       "      <td>0.05457</td>\n",
       "      <td>0.05482</td>\n",
       "      <td>13425624.0</td>\n",
       "      <td>0.054363</td>\n",
       "      <td>61.190849</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.055416</td>\n",
       "      <td>0.053853</td>\n",
       "      <td>0.052291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 04:59:59.999</th>\n",
       "      <td>0.05483</td>\n",
       "      <td>0.05540</td>\n",
       "      <td>0.05469</td>\n",
       "      <td>0.05495</td>\n",
       "      <td>13448954.0</td>\n",
       "      <td>0.054481</td>\n",
       "      <td>62.805730</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.055479</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>0.052265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 05:59:59.999</th>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.05508</td>\n",
       "      <td>0.05476</td>\n",
       "      <td>0.05480</td>\n",
       "      <td>11942184.0</td>\n",
       "      <td>0.054546</td>\n",
       "      <td>59.587184</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.055490</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.052261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 06:59:59.999</th>\n",
       "      <td>0.05483</td>\n",
       "      <td>0.05506</td>\n",
       "      <td>0.05474</td>\n",
       "      <td>0.05478</td>\n",
       "      <td>11621543.0</td>\n",
       "      <td>0.054593</td>\n",
       "      <td>59.132637</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.055553</td>\n",
       "      <td>0.053899</td>\n",
       "      <td>0.052244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01 07:59:59.999</th>\n",
       "      <td>0.05478</td>\n",
       "      <td>0.05523</td>\n",
       "      <td>0.05472</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>9376922.0</td>\n",
       "      <td>0.054658</td>\n",
       "      <td>61.448525</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.053937</td>\n",
       "      <td>0.052224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-20 19:59:59.999</th>\n",
       "      <td>0.62350</td>\n",
       "      <td>0.63480</td>\n",
       "      <td>0.61960</td>\n",
       "      <td>0.63210</td>\n",
       "      <td>55752143.0</td>\n",
       "      <td>0.611113</td>\n",
       "      <td>66.441848</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.627959</td>\n",
       "      <td>0.602170</td>\n",
       "      <td>0.576381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-20 20:59:59.999</th>\n",
       "      <td>0.63220</td>\n",
       "      <td>0.64390</td>\n",
       "      <td>0.62910</td>\n",
       "      <td>0.63720</td>\n",
       "      <td>51886076.0</td>\n",
       "      <td>0.616330</td>\n",
       "      <td>68.621508</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.634163</td>\n",
       "      <td>0.604035</td>\n",
       "      <td>0.573907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-20 21:59:59.999</th>\n",
       "      <td>0.63720</td>\n",
       "      <td>0.64330</td>\n",
       "      <td>0.63530</td>\n",
       "      <td>0.64050</td>\n",
       "      <td>19606479.0</td>\n",
       "      <td>0.621164</td>\n",
       "      <td>70.038137</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.639976</td>\n",
       "      <td>0.606595</td>\n",
       "      <td>0.573214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-20 22:59:59.999</th>\n",
       "      <td>0.64050</td>\n",
       "      <td>0.64450</td>\n",
       "      <td>0.63690</td>\n",
       "      <td>0.64010</td>\n",
       "      <td>26117765.0</td>\n",
       "      <td>0.624951</td>\n",
       "      <td>69.609596</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.644989</td>\n",
       "      <td>0.608670</td>\n",
       "      <td>0.572351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-20 23:59:59.999</th>\n",
       "      <td>0.64020</td>\n",
       "      <td>0.64270</td>\n",
       "      <td>0.63700</td>\n",
       "      <td>0.63990</td>\n",
       "      <td>21153300.0</td>\n",
       "      <td>0.627941</td>\n",
       "      <td>69.370839</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.648825</td>\n",
       "      <td>0.611225</td>\n",
       "      <td>0.573625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36233 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Open     High      Low    Close      Volume  \\\n",
       "closetime                                                                 \n",
       "2020-02-01 03:59:59.999  0.05516  0.05538  0.05457  0.05482  13425624.0   \n",
       "2020-02-01 04:59:59.999  0.05483  0.05540  0.05469  0.05495  13448954.0   \n",
       "2020-02-01 05:59:59.999  0.05492  0.05508  0.05476  0.05480  11942184.0   \n",
       "2020-02-01 06:59:59.999  0.05483  0.05506  0.05474  0.05478  11621543.0   \n",
       "2020-02-01 07:59:59.999  0.05478  0.05523  0.05472  0.05492   9376922.0   \n",
       "...                          ...      ...      ...      ...         ...   \n",
       "2024-03-20 19:59:59.999  0.62350  0.63480  0.61960  0.63210  55752143.0   \n",
       "2024-03-20 20:59:59.999  0.63220  0.64390  0.62910  0.63720  51886076.0   \n",
       "2024-03-20 21:59:59.999  0.63720  0.64330  0.63530  0.64050  19606479.0   \n",
       "2024-03-20 22:59:59.999  0.64050  0.64450  0.63690  0.64010  26117765.0   \n",
       "2024-03-20 23:59:59.999  0.64020  0.64270  0.63700  0.63990  21153300.0   \n",
       "\n",
       "                              EMA        RSI      MACD  BB_UPPER  BB_MIDDLE  \\\n",
       "closetime                                                                     \n",
       "2020-02-01 03:59:59.999  0.054363  61.190849  0.000228  0.055416   0.053853   \n",
       "2020-02-01 04:59:59.999  0.054481  62.805730  0.000254  0.055479   0.053872   \n",
       "2020-02-01 05:59:59.999  0.054546  59.587184  0.000262  0.055490   0.053875   \n",
       "2020-02-01 06:59:59.999  0.054593  59.132637  0.000263  0.055553   0.053899   \n",
       "2020-02-01 07:59:59.999  0.054658  61.448525  0.000271  0.055651   0.053937   \n",
       "...                           ...        ...       ...       ...        ...   \n",
       "2024-03-20 19:59:59.999  0.611113  66.441848  0.000264  0.627959   0.602170   \n",
       "2024-03-20 20:59:59.999  0.616330  68.621508  0.002473  0.634163   0.604035   \n",
       "2024-03-20 21:59:59.999  0.621164  70.038137  0.004439  0.639976   0.606595   \n",
       "2024-03-20 22:59:59.999  0.624951  69.609596  0.005897  0.644989   0.608670   \n",
       "2024-03-20 23:59:59.999  0.627941  69.370839  0.006956  0.648825   0.611225   \n",
       "\n",
       "                         BB_LOWER  \n",
       "closetime                          \n",
       "2020-02-01 03:59:59.999  0.052291  \n",
       "2020-02-01 04:59:59.999  0.052265  \n",
       "2020-02-01 05:59:59.999  0.052261  \n",
       "2020-02-01 06:59:59.999  0.052244  \n",
       "2020-02-01 07:59:59.999  0.052224  \n",
       "...                           ...  \n",
       "2024-03-20 19:59:59.999  0.576381  \n",
       "2024-03-20 20:59:59.999  0.573907  \n",
       "2024-03-20 21:59:59.999  0.573214  \n",
       "2024-03-20 22:59:59.999  0.572351  \n",
       "2024-03-20 23:59:59.999  0.573625  \n",
       "\n",
       "[36233 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for name in df0.columns:\n",
    "  data[name] = np.log(df0[name]).diff()\n",
    "df_returns = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "Ntest = 1000\n",
    "train_data = df_returns.iloc[:-Ntest]\n",
    "test_data = df_returns.iloc[-Ntest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['AAPL', 'MSFT', 'AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "    self.n = len(df)\n",
    "    self.current_idx = 0\n",
    "    self.action_space = [0, 1, 2] # BUY, SELL, HOLD\n",
    "    self.invested = 0\n",
    "\n",
    "    self.states = self.df[feats].to_numpy()\n",
    "    self.rewards = self.df['SPY'].to_numpy()\n",
    "\n",
    "  def reset(self):\n",
    "    self.current_idx = 0\n",
    "    return self.states[self.current_idx]\n",
    "\n",
    "  def step(self, action):\n",
    "    # need to return (next_state, reward, done)\n",
    "\n",
    "    self.current_idx += 1\n",
    "    if self.current_idx >= self.n:\n",
    "      raise Exception(\"Episode already done\")\n",
    "\n",
    "    if action == 0: # BUY\n",
    "      self.invested = 1\n",
    "    elif action == 1: # SELL\n",
    "      self.invested = 0\n",
    "    \n",
    "    # compute reward\n",
    "    if self.invested:\n",
    "      reward = self.rewards[self.current_idx]\n",
    "    else:\n",
    "      reward = 0\n",
    "\n",
    "    # state transition\n",
    "    next_state = self.states[self.current_idx]\n",
    "\n",
    "    done = (self.current_idx == self.n - 1)\n",
    "    return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateMapper:\n",
    "  def __init__(self, env, n_bins=6, n_samples=10000):\n",
    "    # first, collect sample states from the environment\n",
    "    states = []\n",
    "    done = False\n",
    "    s = env.reset()\n",
    "    self.D = len(s) # number of elements we need to bin\n",
    "    states.append(s)\n",
    "    while True:\n",
    "      a = np.random.choice(env.action_space)\n",
    "      s2, _, done = env.step(a)\n",
    "      states.append(s2)\n",
    "      if len(states) >= n_samples:\n",
    "        break\n",
    "      if done:\n",
    "        s = env.reset()\n",
    "        states.append(s)\n",
    "        if len(states) >= n_samples:\n",
    "          break\n",
    "\n",
    "    # convert to numpy array for easy indexing\n",
    "    states = np.array(states)\n",
    "\n",
    "    # create the bins for each dimension\n",
    "    self.bins = []\n",
    "    for d in range(self.D):\n",
    "      column = np.sort(states[:,d])\n",
    "\n",
    "      # find the boundaries for each bin\n",
    "      current_bin = []\n",
    "      for k in range(n_bins):\n",
    "        boundary = column[int(n_samples / n_bins * (k + 0.5))]\n",
    "        current_bin.append(boundary)\n",
    "\n",
    "      self.bins.append(current_bin)\n",
    "\n",
    "\n",
    "  def transform(self, state):\n",
    "    x = np.zeros(self.D)\n",
    "    for d in range(self.D):\n",
    "      x[d] = int(np.digitize(state[d], self.bins[d]))\n",
    "    return tuple(x)\n",
    "\n",
    "\n",
    "  def all_possible_states(self):\n",
    "    list_of_bins = []\n",
    "    for d in range(self.D):\n",
    "      list_of_bins.append(list(range(len(self.bins[d]) + 1)))\n",
    "    # print(list_of_bins)\n",
    "    return itertools.product(*list_of_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "  def __init__(self, action_size, state_mapper):\n",
    "    self.action_size = action_size\n",
    "    self.gamma = 0.8  # discount rate\n",
    "    self.epsilon = 0.1\n",
    "    self.learning_rate = 1e-1\n",
    "    self.state_mapper = state_mapper\n",
    "\n",
    "    # initialize Q-table randomly\n",
    "    self.Q = {}\n",
    "    for s in self.state_mapper.all_possible_states():\n",
    "      s = tuple(s)\n",
    "      for a in range(self.action_size):\n",
    "        self.Q[(s,a)] = np.random.randn()\n",
    "\n",
    "  def act(self, state):\n",
    "    if np.random.rand() <= self.epsilon:\n",
    "      return np.random.choice(self.action_size)\n",
    "\n",
    "    s = self.state_mapper.transform(state)\n",
    "    act_values = [self.Q[(s,a)] for a in range(self.action_size)]\n",
    "    return np.argmax(act_values)  # returns action\n",
    "\n",
    "  def train(self, state, action, reward, next_state, done):\n",
    "    s = self.state_mapper.transform(state)\n",
    "    s2 = self.state_mapper.transform(next_state)\n",
    "\n",
    "    if done:\n",
    "      target = reward\n",
    "    else:\n",
    "      act_values = [self.Q[(s2,a)] for a in range(self.action_size)]\n",
    "      target = reward + self.gamma * np.amax(act_values)\n",
    "\n",
    "    # Run one training step\n",
    "    self.Q[(s,action)] += self.learning_rate * (target - self.Q[(s,action)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_episode(agent, env, is_train):\n",
    "  state = env.reset()\n",
    "  done = False\n",
    "  total_reward = 0\n",
    "\n",
    "  while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done = env.step(action)\n",
    "    total_reward += reward\n",
    "    if is_train:\n",
    "      agent.train(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "\n",
    "  return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = Env(train_data)\n",
    "test_env = Env(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = len(train_env.action_space)\n",
    "state_mapper = StateMapper(train_env)\n",
    "agent = Agent(action_size, state_mapper)\n",
    "train_rewards = np.empty(num_episodes)\n",
    "test_rewards = np.empty(num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(num_episodes):\n",
    "  r = play_one_episode(agent, train_env, is_train=True)\n",
    "  train_rewards[e] = r\n",
    "\n",
    "  # test on the test set\n",
    "  tmp_epsilon = agent.epsilon\n",
    "  agent.epsilon = 0.\n",
    "  tr = play_one_episode(agent, test_env, is_train=False)\n",
    "  agent.epsilon = tmp_epsilon\n",
    "  test_rewards[e] = tr\n",
    "\n",
    "  print(f\"eps: {e + 1}/{num_episodes}, train: {r:.5f}, test: {tr:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
